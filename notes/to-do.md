# To-do list

1. Find better ways to tune the random forest model. (explore parameters)
2. Find out the difference between cross validation and train-test split, and which suits our purpose better.
3. Find which scoring method(f1 vs roc-auc) to use for cross validation, as well as the required k value.
4. Manual is done, now find automated way to decide which parameters are significant for the training set, independent of the test set in cross validation. (see: nested cross validation, [this](https://machinelearningmastery.com/nested-cross-validation-for-machine-learning-with-python/) and [this](https://mlfromscratch.com/nested-cross-validation-python-code/#/)
5. Compare all models using cross validation as well.
